# -*- coding: utf-8 -*-
"""Tubes SI_Kelompok1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bK2o988mts820hgVQZYx99lM-E-vV3-u
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os

# Importing data
df = pd.read_csv('/content/vaccinations.csv')
df.head()

# Deleting the first line
df = df.iloc[1: , :]
df.head()

# Checking the types of data
df.info()

# Changeing the data type of 'total_vaccinations' and 'daily_vaccinations'
df.loc[:,'total_vaccinations'] = pd.to_numeric(df.loc[:,'total_vaccinations'])
df.loc[:,'daily_vaccinations'] = pd.to_numeric(df.loc[:,'daily_vaccinations'])
df.info()

# Checking the unique iso_code
df['iso_code'].unique()

# Dividing the dataset into country and group datasets
df_group = df[df['iso_code'].str.contains('OWID')]
df_group['iso_code'].unique()

df_country = df[df["iso_code"].str.contains("OWID")==False]
df_country['iso_code'].unique()

# The total numbers of vaccinated people are accumulated.
df_country_total = df_country.groupby("location").last().sort_values(by='total_vaccinations',ascending=False)
df_country_total

# people_fully_vaccinated and daily_vaccinations_raw have a lot of missing values
df_country_total.isnull().sum()

# Creating the fuction for adding values in the barplot
def show_values_on_bars(axs, h_v="v", space=0.4):
    def _show_on_single_plot(ax):
        if h_v == "v":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() / 2
                _y = p.get_y() + p.get_height()
                value = int(p.get_height())
                ax.text(_x, _y, value, ha="center")
        elif h_v == "h":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() + float(space)
                _y = p.get_y() + p.get_height()
                value = int(p.get_width())
                ax.text(_x, _y, value, ha="left")

    if isinstance(axs, np.ndarray):
        for idx, ax in np.ndenumerate(axs):
            _show_on_single_plot(ax)
    else:
        _show_on_single_plot(axs)
# Visualizing the data with their values
f, ax = plt.subplots(figsize = (10,40))
fig = sns.barplot(y= df_country_total.index, x= df_country_total['total_vaccinations'], data = df_country_total)
show_values_on_bars(fig, "h", 0.3)

# Seeking the extreme ends
p95 = np.percentile(df_country_total['total_vaccinations'], 95)
p5 = np.percentile(df_country_total['total_vaccinations'], 5)
level = []
for row in df_country_total['total_vaccinations']:
    if row >= p95  :
        level.append('H')
    elif row <= p5:
        level.append('L')
    else:
        level.append('Not_Rated')

df_country_total['level'] = level
df_low = df_country_total[df_country_total['level'] == 'L']
df_high = df_country_total[df_country_total['level'] == 'H']

fig, ax = plt.subplots(2,1)
sns.set_color_codes('pastel')

_ = sns.barplot(y= df_high.index, x= df_high['total_vaccinations']/1000000,
            data = df_high, ax=ax[0])
_ = ax[0].set_title("Highest Number of Total Vaccinations Countries (>95 percentile)")
_ = ax[0].set_xlabel('Total Vaccinations (in millions)')

_ = sns.barplot(y= df_low.index, x= df_low['total_vaccinations']/1000000,
            data = df_low, ax=ax[1])
_ = ax[1].set_title("Lowest Number of Total Vaccinations Countries (<5 percentile)")
_ = ax[1].set_xlabel('Total Vaccinations (in millions)')

_ = plt.subplots_adjust(hspace= 0.5)

fig.set_size_inches(15, 7)
fig.show()

df_group['location'].unique()

# Subsetting World and 6 continents from 'location' column
world_covid_trend = df_group[df_group['location'] == 'World']
df_Asia = df_group[df_group['location'] == 'Asia']
df_Africa = df_group[df_group['location'] == 'Africa']
df_Europe = df_group[df_group['location'] == 'Europe']
df_North_America = df_group[df_group['location'] == 'North America']
df_South_America = df_group[df_group['location'] == 'South America']
df_Oceania = df_group[df_group['location'] == 'Oceania']

# size of the entire plot
plt.figure(figsize=(50, 25))
# x and y axis label names
# title of the plot and its size
plt.title('COVID Vaccination Trend', fontweight='bold', fontsize=40)
plt.xlabel('Date', fontweight='bold')
plt.ylabel('# OF Total Vaccination (in billion)', fontweight='bold')
plt.plot('date', 'total_vaccinations', data = world_covid_trend, \
         c='black', linewidth = 4, label = 'World')
plt.plot('date', 'total_vaccinations', data = df_Asia, \
         c='blue', linewidth = 4, label = 'Asia')
plt.plot('date', 'total_vaccinations', data = df_Africa, \
         c='red', linewidth = 4, label = 'Africa')
plt.plot('date', 'total_vaccinations', data = df_Europe, \
         c='green', linewidth = 4, label = 'Europe')
plt.plot('date', 'total_vaccinations', data = df_North_America, \
         c='orange', linewidth = 4, label = 'North America')
plt.plot('date', 'total_vaccinations', data = df_South_America, \
         c='purple', linewidth = 4, label = 'South America')
plt.xticks(rotation = 70, fontsize = '10')
plt.yticks(fontsize = '20')
# legend position and size
plt.legend(loc='upper left', prop={'size':35})
plt.grid(False)
# axes label font size change
axes = plt. gca()
axes. xaxis. label. set_size(30)
axes. yaxis. label. set_size(30)
plt.show()

# Import library yang dibutuhkan
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping  #

# Memilih fitur yang akan digunakan
features = ['date', 'total_vaccinations', 'daily_vaccinations']  # Menyimpan list fitur yang akan digunakan
df_country = df[df['iso_code'].str.contains('OWID') == False][features]  # Memfilter data untuk menghapus baris yang mengandung 'OWID' dalam kolom iso_code dan hanya mengambil kolom yang terdapat dalam list features

# Menangani missing value
df_country = df_country.dropna()

# Mengonversi 'date' ke datetime dan membuat fitur numerik
df_country['date'] = pd.to_datetime(df_country['date'])  # Mengonversi kolom 'date' menjadi tipe data datetime
df_country['day_of_year'] = df_country['date'].dt.dayofyear  # Membuat kolom baru 'day_of_year' yang berisi hari keberapa dalam setahun
df_country['day_of_week'] = df_country['date'].dt.dayofweek  # Membuat kolom baru 'day_of_week' yang berisi hari keberapa dalam seminggu
df_country = df_country.drop(columns=['date'])  # Menghapus kolom 'date'

# Mendefinisikan variabel fitur dan target
X = df_country.drop(columns=['total_vaccinations'])  # Menyimpan semua kolom kecuali 'total_vaccinations' ke dalam variabel X sebagai fitur
y = df_country['total_vaccinations']  # Menyimpan kolom 'total_vaccinations' ke dalam variabel y sebagai target

# Normalisasi fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Membagi data menjadi set train dan test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Membangun Model
model = Sequential([  # Membuat model berurutan dengan tiga lapisan
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Lapisan pertama dengan 64 neuron dan fungsi aktivasi ReLU
    Dropout(0.2),  # Menambahkan lapisan dropout dengan rate 0.2
    Dense(32, activation='relu'),  # Lapisan kedua dengan 32 neuron dan fungsi aktivasi ReLU
    Dropout(0.2),  # Menambahkan lapisan dropout dengan rate 0.2
    Dense(1)  # Lapisan output dengan 1 neuron
])

# Melatih Model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(X_train, y_train, validation_split=0.2, epochs=500, callbacks=[early_stopping], batch_size=32)

# Mengevaluasi Model
loss, mae = model.evaluate(X_test, y_test)  # Mengevaluasi model menggunakan data train untuk mendapatkan nilai loss dan mean absolute error
print(f"Test MAE: {mae}")

# Memplot train
plt.figure(figsize=(12, 6))  # Membuat gambar berukuran 12x6
plt.plot(history.history['loss'], label='Train Loss')  # Memplot nilai loss train
plt.plot(history.history['val_loss'], label='Validation Loss')  # Memplot nilai loss validasi
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))  # Membuat gambar berukuran 12x6
plt.plot(history.history['mean_absolute_error'], label='Train MAE')  # Memplot nilai mean absolute error train
plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')  # Memplot nilai mean absolute error validasi
plt.xlabel('Epochs')
plt.ylabel('MAE')
plt.legend()
plt.show()

# Prediksi
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# Menghitung metrik kesalahan
train_mae = mean_absolute_error(y_train, y_pred_train)  # Menghitung mean absolute error pada data train
train_mse = mean_squared_error(y_train, y_pred_train)  # Menghitung mean squared error pada data train
train_rmse = np.sqrt(train_mse)  # Menghitung root mean squared error pada data train

test_mae = mean_absolute_error(y_test, y_pred_test)  # Menghitung mean absolute error pada data test
test_mse = mean_squared_error(y_test, y_pred_test)  # Menghitung mean squared error pada data test
test_rmse = np.sqrt(test_mse)  # Menghitung root mean squared error pada data test

print(f"Train Mean Absolute Error: {train_mae}")
print(f"Train Mean Squared Error: {train_mse}")
print(f"Train Root Mean Squared Error: {train_rmse}")

print(f"Test Mean Absolute Error: {test_mae}")
print(f"Test Mean Squared Error: {test_mse}")
print(f"Test Root Mean Squared Error: {test_rmse}")

# Korelasi antara nilai aktual dan prediksi
train_corr = np.corrcoef(y_train, y_pred_train[:, 0])[0, 1]  # Menghitung korelasi antara nilai aktual dan prediksi pada data train
test_corr = np.corrcoef(y_test, y_pred_test[:, 0])[0, 1]  # Menghitung korelasi antara nilai aktual dan prediksi pada data test

print(f"Train Correlation: {train_corr}")
print(f"Test Correlation: {test_corr}")

# Memplot data train
plt.figure(figsize=(12, 6))  # Membuat gambar berukuran 12x6 inci

plt.plot(history.history['loss'], label='Train Loss')  # Memplot nilai loss pada data train, dengan label 'Train Loss'
plt.plot(history.history['val_loss'], label='Validation Loss')  # Memplot nilai loss pada data validasi, dengan label 'Validation Loss'

plt.xlabel('Epochs')  # Menambahkan label 'Epochs' pada sumbu x
plt.ylabel('Loss')  # Menambahkan label 'Loss' pada sumbu y
plt.legend()  # Menambahkan legenda untuk membedakan antara 'Train Loss' dan 'Validation Loss'

plt.show()  # Menampilkan plot

# Mencetak hasil korelasi data train dan test
print(f"Train Correlation: {train_corr}")
print(f"Test Correlation: {test_corr}")

"""##ALGORITMA FIREFLY"""

import random

# Memilih fitur yang relevan
features = ['date', 'total_vaccinations', 'daily_vaccinations']  # Menyimpan list fitur yang akan digunakan
df_country = df[df['iso_code'].str.contains('OWID') == False][features]  # Memfilter data untuk menghapus baris yang mengandung 'OWID' pada kolom iso_code dan hanya mengambil kolom yang terdapat dalam features

# Menangani missing value
df_country = df_country.dropna()  # Menghapus semua baris yang memiliki nilai NaN

df_country['date'] = pd.to_datetime(df_country['date'])  # Mengonversi kolom 'date' menjadi tipe data datetime
df_country['day_of_year'] = df_country['date'].dt.dayofyear  # Membuat kolom baru 'day_of_year' yang berisi hari keberapa dalam setahun
df_country['day_of_week'] = df_country['date'].dt.dayofweek  # Membuat kolom baru 'day_of_week' yang berisi hari keberapa dalam seminggu
df_country = df_country.drop(columns=['date'])  # Menghapus kolom 'date'

# Mendefinisikan fitur dan target
X = df_country.drop(columns=['total_vaccinations'])  # Menyimpan semua kolom kecuali 'total_vaccinations' ke dalam variabel X sebagai fitur
y = df_country['total_vaccinations']  # Menyimpan kolom 'total_vaccinations' ke dalam variabel y sebagai target

# Menormalisasi
scaler = StandardScaler()  # Membuat objek StandardScaler untuk normalisasi data
X_scaled = scaler.fit_transform(X)  # Menormalkan data X dan menyimpan hasilnya ke dalam variabel X_scaled

# Split data train dan data test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)  # Membagi data menjadi set train 80% dan set test 20%

# Parameter Algoritma Firefly
n_fireflies = 10  # Jumlah firefly adalah 10
max_gen = 20  # Jumlah generasi maksimum adalah 20
alpha = 0.5  # Mengatur parameter alpha yang mengontrol intensitas gerakan acak firefly
beta0 = 1  # Mengatur nilai awal beta yang menentukan daya tarik antar firefly
gamma = 1  # Mengatur parameter gamma yang mengontrol tingkat pengurangan daya tarik
dim = 2  # Menentukan dimensi solusi menjadi 2, yaitu jumlah neuron di lapisan pertama dan kedua

# Insialisasi firefly
fireflies = np.random.randint(10, 100, (n_fireflies, dim))
fitness = np.zeros(n_fireflies)

# Fungsi untuk mengevaluasi kecocokan (1 / MSE)
def evaluate_fitness(params):  # Mendefinisikan fungsi untuk mengevaluasi kecocokan firefly berdasarkan parameter jumlah neuron
    n_neurons_1, n_neurons_2 = params  # Mendeklarasikan dua parameter yang merepresentasikan jumlah neuron di lapisan pertama dan kedua

    model = Sequential([  # Mendefinisikan arsitektur model neural network
        Dense(n_neurons_1, activation='relu', input_shape=(X_train.shape[1],)),  # Lapisan pertama dengan n_neurons_1 neuron dan aktivasi ReLU
        Dropout(0.2),  # Menambahkan lapisan dropout dengan rate 0.2
        Dense(n_neurons_2, activation='relu'),  # Lapisan kedua dengan n_neurons_2 neuron dan aktivasi ReLU
        Dropout(0.2),  # Menambahkan lapisan dropout dengan rate 0.2
        Dense(1)  # Lapisan output dengan 1 neuron
    ])

    model.compile(optimizer='adam', loss='mean_squared_error')  # Mengompilasi model dengan optimizer 'adam' dan fungsi loss 'mean_squared_error'
    model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0)  # Melatih model dengan data pelatihan selama 10 epoch

    y_pred = model.predict(X_test)  # Memprediksi data uji menggunakan model yang telah dilatih
    mse = mean_squared_error(y_test, y_pred)  # Menghitung nilai Mean Squared Error (MSE) dari prediksi
    return 1 / mse  # Mengembalikan nilai kecocokan sebagai kebalikan dari MSE

# Algoritma Firefly
for gen in range(max_gen):
    for i in range(n_fireflies):
        fitness[i] = evaluate_fitness(fireflies[i])  # Menghitung dan menyimpan kecocokan setiap firefly

    for i in range(n_fireflies):  # Melakukan iterasi melalui setiap firefly untuk memperbarui posisi firefly
        for j in range(n_fireflies):  # Membandingkan setiap firefly dengan firefly lainnya
            if fitness[i] < fitness[j]:
                r = np.linalg.norm(fireflies[i] - fireflies[j])  # Menghitung jarak antara firefly i dan j
                beta = beta0 * np.exp(-gamma * r**2)  # Menghitung daya tarik antara firefly i dan j
                fireflies[i] = fireflies[i] + beta * (fireflies[j] - fireflies[i]) + alpha * (np.random.rand(dim) - 0.5)  # Memperbarui posisi firefly i

# Mendapatkan solusi terbaik
best_firefly = fireflies[np.argmax(fitness)]  # Menentukan firefly dengan nilai kecocokan terbaik
n_neurons_1, n_neurons_2 = best_firefly  # Menyimpan jumlah neuron di lapisan pertama dan kedua dari firefly terbaik

# Melatih model akhir dengan parameter terbaik
model = Sequential([
    Dense(n_neurons_1, activation='relu', input_shape=(X_train.shape[1],)),  # Lapisan pertama dengan n_neurons_1 neuron dan aktivasi ReLU
    Dropout(0.2),  # Menambahkan lapisan dropout dengan rate 0.2
    Dense(n_neurons_2, activation='relu'),  # Lapisan kedua dengan n_neurons_2 neuron dan aktivasi ReLU
    Dropout(0.2),  # Menambahkan lapisan dropout dengan rate 0.2
    Dense(1)  # Lapisan output dengan 1 neuron
])

model.compile(optimizer='adam', loss='mean_squared_error')  # Mengompilasi model dengan optimizer 'adam' dan fungsi loss 'mean_squared_error'
model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0)  # Melatih model final dengan data train selama 10 epoch

# Evaluasi model
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mse)

print(f"Best Neurons Layer 1: {n_neurons_1}")
print(f"Best Neurons Layer 2: {n_neurons_2}")

import pandas as pd
import matplotlib.pyplot as plt
from pandas.plotting import scatter_matrix

# Asumsi df_country telah diproses sesuai langkah sebelumnya
# Memilih fitur yang relevan
features = ['total_vaccinations', 'day_of_year', 'day_of_week']  # Menyimpan daftar fitur yang akan digunakan
df_vaccinations = df_country[features]  # Membuat DataFrame baru yang hanya berisi fitur yang dipilih dari df_country

def plotScatterMatrix(df, alpha=0.5, size=10):
    # Memplot scatter matrix
    scatter_matrix(df, alpha=alpha, figsize=(size, size), diagonal='kde')  # Membuat scatter matrix dengan kekuatan transparansi alpha dan ukuran gambar size, serta menggunakan KDE untuk histogram diagonal

plt.figure(figsize=(12, 6))  \
sns.histplot(df_vaccinations['total_vaccinations'], kde=True)  # Membuat histogram dari 'total_vaccinations' dengan KDE (Kernel Density Estimate)
plt.title('Distribution of Total Vaccinations')
plt.xlabel('Total Vaccinations')  # Menambahkan label 'Total Vaccinations' pada sumbu x
plt.ylabel('Frequency')  # Menambahkan label 'Frequency' pada sumbu y
plt.show()  # Menampilkan plot



import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import tensorflow as tf

# Parameter Algoritma Firefly
n_fireflies = 10
max_gen = 20
alpha = 0.5
beta0 = 1
gamma = 1
dim = 2

# Menginisialisasi firefly
fireflies = np.random.randint(10, 100, (n_fireflies, dim))  # Menghasilkan firefly dengan neuron antara 10 hingga 100
fitness = np.zeros(n_fireflies)  # Menyimpan nilai fitness
accuracies = np.zeros(n_fireflies)  # Menyimpan nilai akurasi

# Fungsi untuk mengevaluasi fitness (1 / MSE)
def evaluate_fitness(params, X_train, y_train, X_test, y_test):
    from tensorflow.keras.models import Sequential  # Mengimpor API Sequential untuk membuat model neural network berurutan
    from tensorflow.keras.layers import Dense, Dropout  # Mengimpor lapisan Dense dan Dropout dari Keras
    from tensorflow.keras.callbacks import EarlyStopping  # Mengimpor callback untuk menghentikan pelatihan lebih awal jika performa tidak meningkat

    n_neurons_1, n_neurons_2 = params  # Mendekode jumlah neuron dari parameter

    model = Sequential([
        Dense(n_neurons_1, activation='relu', input_shape=(X_train.shape[1],)),
        Dropout(0.2),
        Dense(n_neurons_2, activation='relu'),
        Dropout(0.2),
        Dense(1)
    ])

    y_pred = model.predict(X_test)  # Membuat prediksi pada data test
    mse = mean_squared_error(y_test, y_pred)  # Menghitung mean squared error
    mae = mean_absolute_error(y_test, y_pred)  # Menghitung mean absolute error
    rmse = np.sqrt(mse)  # Menghitung root mean squared error
    r2 = r2_score(y_test, y_pred)  # Menghitung R-squared (koefisien determinasi)
    accuracy = r2  # Menggunakan R-squared sebagai proxy untuk akurasi pada tugas regresi

    return 1 / mse, accuracy  # Mengembalikan nilai fitness dan akurasi

# Algoritma Firefly
def firefly_algorithm(X_train, y_train, X_test, y_test):
    global fireflies, fitness, accuracies
    for gen in range(max_gen):  # Untuk setiap generasi
        for i in range(n_fireflies):  # Untuk setiap firefly
            fitness[i], accuracies[i] = evaluate_fitness(fireflies[i], X_train, y_train, X_test, y_test)  # Mengevaluasi fitness dan akurasi

        for i in range(n_fireflies):  # Untuk setiap firefly
            for j in range(n_fireflies):  # Bandingkan dengan setiap firefly lainnya
                if fitness[i] < fitness[j]:  # Jika firefly i memiliki fitness lebih buruk
                    r = np.linalg.norm(fireflies[i] - fireflies[j])  # Menghitung jarak Euclidean antara dua firefly
                    beta = beta0 * np.exp(-gamma * r**2)  # Menghitung nilai beta berdasarkan jarak
                    fireflies[i] = fireflies[i] + beta * (fireflies[j] - fireflies[i]) + alpha * (np.random.rand(dim) - 0.5)  # Perbarui posisi firefly

    best_firefly_index = np.argmax(fitness)  # Mendapatkan indeks firefly terbaik berdasarkan fitness tertinggi
    best_firefly = fireflies[best_firefly_index]  # Mendapatkan parameter firefly terbaik
    best_accuracy = accuracies[best_firefly_index]  # Mendapatkan nilai akurasi terbaik
    return best_firefly, best_accuracy  # Mengembalikan parameter terbaik dan akurasi terbaik

# Contoh penggunaan dengan data Anda (X_train, y_train, X_test, y_test)
best_hyperparams, best_accuracy = firefly_algorithm(X_train, y_train, X_test, y_test)
n_neurons_1, n_neurons_2 = best_hyperparams

print(f"Best Neurons Layer 1: {n_neurons_1}")
print(f"Best Neurons Layer 2: {n_neurons_2}")
print(f"Best Accuracy (R-squared): {best_accuracy}")